{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b434cdf",
   "metadata": {},
   "source": [
    "# Basics of PySpark compared with Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "5d69427f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "94aba0a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('Practice').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "731e7682",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.0.103:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Practice</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fa8392b4820>"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "36094536",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spark = spark.read.csv('Department_Dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "3aa1c62c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pandas = pd.read_csv('Department_Dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "f18da981",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[_c0: string, _c1: string, _c2: string, _c3: string]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "6e48c078",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+---------+---------------+\n",
      "|_c0|      _c1|      _c2|            _c3|\n",
      "+---+---------+---------+---------------+\n",
      "| ID|Dept_name| location|travel_required|\n",
      "|  1|       HR|     Pune|            yes|\n",
      "|  2|  Finance|Bangalore|             no|\n",
      "|  3|  Finance|Bangalore|             no|\n",
      "|  4|  Finance|     Pune|             no|\n",
      "+---+---------+---------+---------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_spark.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25cc6cc9",
   "metadata": {},
   "source": [
    "### To read first row as header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "77d6fa21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Dept_name</th>\n",
       "      <th>location</th>\n",
       "      <th>travel_required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>HR</td>\n",
       "      <td>Pune</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Finance</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Finance</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Finance</td>\n",
       "      <td>Pune</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Tech</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID Dept_name   location travel_required\n",
       "0   1        HR       Pune             yes\n",
       "1   2   Finance  Bangalore              no\n",
       "2   3   Finance  Bangalore              no\n",
       "3   4   Finance       Pune              no\n",
       "4   5      Tech     Mumbai              no"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pandas.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "6c3d64af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[ID: string, Dept_name: string, location: string, travel_required: string]"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_spark = spark.read.option('header','true').csv('Department_Dataset.csv')\n",
    "df_spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "db9ae1f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+---------+---------------+\n",
      "| ID|Dept_name| location|travel_required|\n",
      "+---+---------+---------+---------------+\n",
      "|  1|       HR|     Pune|            yes|\n",
      "|  2|  Finance|Bangalore|             no|\n",
      "|  3|  Finance|Bangalore|             no|\n",
      "|  4|  Finance|     Pune|             no|\n",
      "|  5|     Tech|   Mumbai|             no|\n",
      "+---+---------+---------+---------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_spark.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a254e1d0",
   "metadata": {},
   "source": [
    "### To read more information on dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "6a8d7e45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 35 entries, 0 to 34\n",
      "Data columns (total 4 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   ID               35 non-null     int64 \n",
      " 1   Dept_name        35 non-null     object\n",
      " 2   location         35 non-null     object\n",
      " 3   travel_required  35 non-null     object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 1.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df_pandas.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "dacc8f4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ID: string (nullable = true)\n",
      " |-- Dept_name: string (nullable = true)\n",
      " |-- location: string (nullable = true)\n",
      " |-- travel_required: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_spark.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cca413f8",
   "metadata": {},
   "source": [
    "By default all the columns are of datatype string because of the parameter inferSchema=False, set it to True and it will infer the schema automatically"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd269290",
   "metadata": {},
   "source": [
    "# Basic Operations on DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "2742d7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_spark = spark.read.option('header','true').csv('Department_Dataset.csv',inferSchema=True)\n",
    "df_spark = spark.read.csv('Department_Dataset.csv',header=True,inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "dccbc937",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ID: integer (nullable = true)\n",
      " |-- Dept_name: string (nullable = true)\n",
      " |-- location: string (nullable = true)\n",
      " |-- travel_required: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_spark.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "0d54539f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------PySpark-------------\n",
      "+---+---------+---------+---------------+\n",
      "| ID|Dept_name| location|travel_required|\n",
      "+---+---------+---------+---------------+\n",
      "|  1|       HR|     Pune|            yes|\n",
      "|  2|  Finance|Bangalore|             no|\n",
      "|  3|  Finance|Bangalore|             no|\n",
      "|  4|  Finance|     Pune|             no|\n",
      "|  5|     Tech|   Mumbai|             no|\n",
      "+---+---------+---------+---------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "-------------Pandas-------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Dept_name</th>\n",
       "      <th>location</th>\n",
       "      <th>travel_required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>HR</td>\n",
       "      <td>Pune</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Finance</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Finance</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Finance</td>\n",
       "      <td>Pune</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Tech</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID Dept_name   location travel_required\n",
       "0   1        HR       Pune             yes\n",
       "1   2   Finance  Bangalore              no\n",
       "2   3   Finance  Bangalore              no\n",
       "3   4   Finance       Pune              no\n",
       "4   5      Tech     Mumbai              no"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('-------------PySpark-------------')\n",
    "df_spark.show(5)\n",
    "print('-------------Pandas-------------')\n",
    "df_pandas.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "a1dbd00b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------PySpark-------------\n",
      "root\n",
      " |-- ID: integer (nullable = true)\n",
      " |-- Dept_name: string (nullable = true)\n",
      " |-- location: string (nullable = true)\n",
      " |-- travel_required: string (nullable = true)\n",
      "\n",
      "-------------Pandas-------------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 35 entries, 0 to 34\n",
      "Data columns (total 4 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   ID               35 non-null     int64 \n",
      " 1   Dept_name        35 non-null     object\n",
      " 2   location         35 non-null     object\n",
      " 3   travel_required  35 non-null     object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 1.2+ KB\n"
     ]
    }
   ],
   "source": [
    "print('-------------PySpark-------------')\n",
    "df_spark.printSchema()\n",
    "print('-------------Pandas-------------')\n",
    "df_pandas.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "b4ca721d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------PySpark-------------\n",
      "['ID', 'Dept_name', 'location', 'travel_required']\n",
      "-------------Pandas-------------\n",
      "Index(['ID', 'Dept_name', 'location', 'travel_required'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print('-------------PySpark-------------')\n",
    "print(df_spark.columns)\n",
    "print('-------------Pandas-------------')\n",
    "print(df_pandas.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "7ab6a1df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------PySpark-------------\n",
      "[('ID', 'int'), ('Dept_name', 'string'), ('location', 'string'), ('travel_required', 'string')]\n",
      "-------------Pandas-------------\n",
      "ID                  int64\n",
      "Dept_name          object\n",
      "location           object\n",
      "travel_required    object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print('-------------PySpark-------------')\n",
    "print(df_spark.dtypes)\n",
    "print('-------------Pandas-------------')\n",
    "print(df_pandas.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "17c1c35a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------PySpark-------------\n",
      "+-------+------------------+---------+---------+---------------+\n",
      "|summary|                ID|Dept_name| location|travel_required|\n",
      "+-------+------------------+---------+---------+---------------+\n",
      "|  count|                35|       35|       35|             35|\n",
      "|   mean|              18.0|     null|     null|           null|\n",
      "| stddev|10.246950765959598|     null|     null|           null|\n",
      "|    min|                 1|  Finance|Bangalore|             no|\n",
      "|    max|                35|     Tech|     Pune|            yes|\n",
      "+-------+------------------+---------+---------+---------------+\n",
      "\n",
      "None\n",
      "-------------Pandas-------------\n",
      "              ID\n",
      "count  35.000000\n",
      "mean   18.000000\n",
      "std    10.246951\n",
      "min     1.000000\n",
      "25%     9.500000\n",
      "50%    18.000000\n",
      "75%    26.500000\n",
      "max    35.000000\n",
      "               ID Dept_name   location travel_required\n",
      "count   35.000000        35         35              35\n",
      "unique        NaN         3          3               2\n",
      "top           NaN      Tech  Bangalore              no\n",
      "freq          NaN        14         13              22\n",
      "mean    18.000000       NaN        NaN             NaN\n",
      "std     10.246951       NaN        NaN             NaN\n",
      "min      1.000000       NaN        NaN             NaN\n",
      "25%      9.500000       NaN        NaN             NaN\n",
      "50%     18.000000       NaN        NaN             NaN\n",
      "75%     26.500000       NaN        NaN             NaN\n",
      "max     35.000000       NaN        NaN             NaN\n"
     ]
    }
   ],
   "source": [
    "print('-------------PySpark-------------')\n",
    "print(df_spark.describe().show())\n",
    "print('-------------Pandas-------------')\n",
    "print(df_pandas.describe())\n",
    "print(df_pandas.describe(include='all'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "89b3b64f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------PySpark-------------\n",
      "+---------+\n",
      "|Dept_name|\n",
      "+---------+\n",
      "|       HR|\n",
      "|  Finance|\n",
      "|  Finance|\n",
      "|  Finance|\n",
      "|     Tech|\n",
      "+---------+\n",
      "only showing top 5 rows\n",
      "\n",
      "None\n",
      "-------------Pandas-------------\n",
      "0         HR\n",
      "1    Finance\n",
      "2    Finance\n",
      "3    Finance\n",
      "4       Tech\n",
      "Name: Dept_name, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print('-------------PySpark-------------')\n",
    "print(df_spark.select('Dept_name').show(5))\n",
    "print('-------------Pandas-------------')\n",
    "print(df_pandas['Dept_name'].head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "121bb590",
   "metadata": {},
   "source": [
    "### adding column in dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "5544841a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spark = df_spark.withColumn('ID_new',df_spark['ID']*100)\n",
    "df_pandas['ID_new'] = df_pandas['ID']*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "3cdea00b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------PySpark-------------\n",
      "+---+---------+---------+---------------+------+\n",
      "| ID|Dept_name| location|travel_required|ID_new|\n",
      "+---+---------+---------+---------------+------+\n",
      "|  1|       HR|     Pune|            yes|   100|\n",
      "|  2|  Finance|Bangalore|             no|   200|\n",
      "|  3|  Finance|Bangalore|             no|   300|\n",
      "|  4|  Finance|     Pune|             no|   400|\n",
      "|  5|     Tech|   Mumbai|             no|   500|\n",
      "+---+---------+---------+---------------+------+\n",
      "only showing top 5 rows\n",
      "\n",
      "None\n",
      "-------------Pandas-------------\n",
      "   ID Dept_name   location travel_required  ID_new\n",
      "0   1        HR       Pune             yes     100\n",
      "1   2   Finance  Bangalore              no     200\n",
      "2   3   Finance  Bangalore              no     300\n",
      "3   4   Finance       Pune              no     400\n",
      "4   5      Tech     Mumbai              no     500\n"
     ]
    }
   ],
   "source": [
    "print('-------------PySpark-------------')\n",
    "print(df_spark.show(5))\n",
    "print('-------------Pandas-------------')\n",
    "print(df_pandas.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6669ddd4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7a1a3588",
   "metadata": {},
   "source": [
    "### Dropping the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "57046037",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spark = df_spark.drop('ID_new')\n",
    "df_pandas = df_pandas.drop(['ID_new'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "4316e4de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------PySpark-------------\n",
      "+---+---------+---------+---------------+\n",
      "| ID|Dept_name| location|travel_required|\n",
      "+---+---------+---------+---------------+\n",
      "|  1|       HR|     Pune|            yes|\n",
      "|  2|  Finance|Bangalore|             no|\n",
      "|  3|  Finance|Bangalore|             no|\n",
      "|  4|  Finance|     Pune|             no|\n",
      "|  5|     Tech|   Mumbai|             no|\n",
      "+---+---------+---------+---------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "None\n",
      "-------------Pandas-------------\n",
      "   ID Dept_name   location travel_required\n",
      "0   1        HR       Pune             yes\n",
      "1   2   Finance  Bangalore              no\n",
      "2   3   Finance  Bangalore              no\n",
      "3   4   Finance       Pune              no\n",
      "4   5      Tech     Mumbai              no\n"
     ]
    }
   ],
   "source": [
    "print('-------------PySpark-------------')\n",
    "print(df_spark.show(5))\n",
    "print('-------------Pandas-------------')\n",
    "print(df_pandas.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b510835d",
   "metadata": {},
   "source": [
    "### Renaming Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "336fba28",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spark = df_spark.withColumnRenamed('Dept_name','Department_name')\n",
    "df_pandas.rename(columns={'Dept_name':'Department_name'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "af249734",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------PySpark-------------\n",
      "+---+---------------+---------+---------------+\n",
      "| ID|Department_name| location|travel_required|\n",
      "+---+---------------+---------+---------------+\n",
      "|  1|             HR|     Pune|            yes|\n",
      "|  2|        Finance|Bangalore|             no|\n",
      "|  3|        Finance|Bangalore|             no|\n",
      "|  4|        Finance|     Pune|             no|\n",
      "|  5|           Tech|   Mumbai|             no|\n",
      "+---+---------------+---------+---------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "None\n",
      "-------------Pandas-------------\n",
      "   ID Department_name   location travel_required\n",
      "0   1              HR       Pune             yes\n",
      "1   2         Finance  Bangalore              no\n",
      "2   3         Finance  Bangalore              no\n",
      "3   4         Finance       Pune              no\n",
      "4   5            Tech     Mumbai              no\n"
     ]
    }
   ],
   "source": [
    "print('-------------PySpark-------------')\n",
    "print(df_spark.show(5))\n",
    "print('-------------Pandas-------------')\n",
    "print(df_pandas.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1800d5ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
